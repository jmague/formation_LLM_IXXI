{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[comment]: <> \"LTeX: language=fr\"\n",
    "# <center>Dissection d'un transformer</center>\n",
    "## <center>Jean-Philippe Magué, IXXI</center>\n",
    "### <center>21 juin 2024</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[comment]: <> \"LTeX: language=fr\"\n",
    "Ce notebook propose une vision de \"haut niveau\" du fonctionnement du modèle [GPT2](https://huggingface.co/docs/transformers/en/model_doc/gpt2), c'est-à-dire en regardant les entrées et les sorties, mais sans rentrer dans le fonctionnement interne. \n",
    "\n",
    "Il utilise la bibliothèque [transformers](https://huggingface.co/docs/transformers/en/index) de [HuggingFace](https://huggingface.co/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "from transformers import GPT2TokenizerFast, GPT2LMHeadModel\n",
    "import matplotlib.pyplot as plt\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.grad_mode.set_grad_enabled at 0x17a1b2f40>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.set_grad_enabled(False) #no training today!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'openai-community/gpt2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='mps', index=0)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = GPT2TokenizerFast.from_pretrained(model_name)\n",
    "gpt2 = GPT2LMHeadModel.from_pretrained(model_name,device_map=\"auto\",pad_token_id=tokenizer.eos_token_id)\n",
    "device = gpt2.device\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Génération de texte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = 'the cat sat on the'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](img/tokenization/tokenization.001.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[1169, 3797, 3332,  319,  262]], device='mps:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1]], device='mps:0')}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|the| -> 1169\n",
      "| cat| -> 3797\n",
      "| sat| -> 3332\n",
      "| on| -> 319\n",
      "| the| -> 262\n"
     ]
    }
   ],
   "source": [
    "for token in input['input_ids'][0]:\n",
    "    print(f'|{tokenizer.decode(token)}| -> {token}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = gpt2.generate(input_ids=input['input_ids'], attention_mask=input['attention_mask'], max_new_tokens=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1169, 3797, 3332,  319,  262, 4314]], device='mps:0')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1169 -> |the|\n",
      "3797 -> | cat|\n",
      "3332 -> | sat|\n",
      "319 -> | on|\n",
      "262 -> | the|\n",
      "4314 -> | floor|\n"
     ]
    }
   ],
   "source": [
    "for token in output[0]:\n",
    "    print(f'{token} -> |{tokenizer.decode(token)}|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = gpt2.generate(input_ids=input['input_ids'], attention_mask=input['attention_mask'], max_new_tokens=1,return_dict_in_generate=True, output_scores=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-93.6302, -91.2279, -95.6219,  ..., -95.8761, -95.7496, -93.2641]],\n",
       "        device='mps:0'),)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output['scores']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = output['scores'][0].cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score des 10 premiers tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|!| -> -93.6302\n",
      "|\"| -> -91.2279\n",
      "|#| -> -95.6219\n",
      "|$| -> -96.1859\n",
      "|%| -> -95.5137\n",
      "|&| -> -96.0170\n",
      "|'| -> -92.7750\n",
      "|(| -> -92.5709\n",
      "|)| -> -90.8867\n",
      "|*| -> -93.0254\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(f'|{tokenizer.decode(i)}| -> {scores[0,i]:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut transformer ces scores en probabilités via une fonction softmax :\n",
    "\n",
    "$\\sigma(x_i)=\\frac{e^{x_i}}{\\sum{e^{x_j}}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.9344670e-07, 2.1372703e-06, 2.6397579e-08, ..., 2.0473150e-08,\n",
       "       2.3234190e-08, 2.7896203e-07], dtype=float32)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs = torch.nn.functional.softmax(torch.tensor(scores),dim=1)[0].numpy()\n",
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|!| -> 0.00000019\n",
      "|\"| -> 0.00000214\n",
      "|#| -> 0.00000003\n",
      "|$| -> 0.00000002\n",
      "|%| -> 0.00000003\n",
      "|&| -> 0.00000002\n",
      "|'| -> 0.00000045\n",
      "|(| -> 0.00000056\n",
      "|)| -> 0.00000301\n",
      "|*| -> 0.00000035\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(f'|{tokenizer.decode(i)}| -> {probs[i]:.8f}')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " floor -> 0.067\n",
      " couch -> 0.058\n",
      " bed -> 0.055\n",
      " ground -> 0.043\n",
      " edge -> 0.041\n",
      " bench -> 0.035\n",
      " other -> 0.034\n",
      " table -> 0.032\n",
      " sofa -> 0.023\n",
      " back -> 0.015\n"
     ]
    }
   ],
   "source": [
    "tokens_sorted_by_prob=sorted(list(zip([tokenizer.decode(i) for i in range(len(probs))],probs)), key=lambda x: x[1], reverse=True)\n",
    "for i in range(10):\n",
    "    print(f'{tokens_sorted_by_prob[i][0]} -> {tokens_sorted_by_prob[i][1]:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le modèle choisi le token ayant le plus "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Brouillon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jmague/mambaforge/envs/formation_LLM/lib/python3.9/site-packages/transformers/utils/generic.py:311: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "pipe = pipeline(model=model_name, device_map='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Hi language model, how are you\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': \"Hi language model, how are you going to get it?\\n\\nCurtis Molyneux: Well, we really have a very specific language model where you will want to use three types of code, that's what we're building for\"}]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "device=model.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [1169, 3797, 3332, 319, 262], 'attention_mask': [1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|the| -> 1169\n",
      "| cat| -> 3797\n",
      "| sat| -> 3332\n",
      "| on| -> 319\n",
      "| the| -> 262\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[1169, 3797, 3332,  319,  262]], device='mps:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1]], device='mps:0')}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "output = model.generate(input_ids=input['input_ids'], attention_mask=input['attention_mask'], max_new_tokens=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1169, 3797, 3332,  319,  262, 4314]], device='mps:0')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1169 -> |the|\n",
      "3797 -> | cat|\n",
      "3332 -> | sat|\n",
      "319 -> | on|\n",
      "262 -> | the|\n",
      "4314 -> | floor|\n"
     ]
    }
   ],
   "source": [
    "for token in model_output[0]:\n",
    "    print(f'{token} -> |{tokenizer.decode(token)}|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GenerationConfig {\n",
       "  \"bos_token_id\": 50256,\n",
       "  \"eos_token_id\": 50256\n",
       "}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.generation_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "model_output = model.generate(**model_input, output_scores=True,return_dict_in_generate=True, max_new_tokens=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_output' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel_output\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscores\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model_output' is not defined"
     ]
    }
   ],
   "source": [
    "model_output['scores'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = torch.nn.functional.softmax(model_output['scores'][0][0],dim=0).cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2aaf327c0>]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(sorted(probs),'.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token 534 : | your| p=0.2561\n",
      "token 262 : | the| p=0.0972\n",
      "token 257 : | a| p=0.0461\n",
      "token 428 : | this| p=0.0454\n",
      "token 326 : | that| p=0.0316\n"
     ]
    }
   ],
   "source": [
    "for token in torch.topk(model_output['scores'][0], k=5).indices[0]:\n",
    "    print(f'token {token} : |{tokenizer.decode(token)}| p={probs[token]:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = 'the cat sat on the'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [1169, 3797, 3332, 319, 262], 'attention_mask': [1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids=tokenizer(prompt, return_tensors=\"pt\").to(device)['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1169, 3797, 3332,  319,  262, 4314]], device='mps:0')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.generate(input_ids=input_ids,attention_mask=max_new_tokens=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
